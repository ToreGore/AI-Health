{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Densnet for ISIC Skin Cancer Dataset\n",
    "## Imports:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Dense\n",
    "from tensorflow.keras.layers import AvgPool2D, GlobalAveragePooling2D, MaxPool2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import ReLU, concatenate\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np                                    \n",
    "import pandas as pd \n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelBinarizer\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "source": [
    "## Densnet Model (own)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def densenet(input_shape, n_classes, filters = 32):\n",
    "  # Same sequence for each convolutional block after the input\n",
    "  # Batch normalization, ReLu activation + Conv2D layer\n",
    "  def bn_rl_conv(x, filters, kernel=1, strides=1):\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(filters, kernel, strides=strides, padding = \"same\")(x)\n",
    "    return x\n",
    "  \n",
    "  def dense_block(x, repetition):\n",
    "    # Each dense block has 2 convolutions with 1x1 and 3x3 kernels\n",
    "    # 1st dense block with 6 repetitions\n",
    "    # 2nd dense block with 12 repetiotions\n",
    "    # 3rd dense block with 24 repetitions\n",
    "    # 4th dense block with 16 repetitions\n",
    "\n",
    "    # Each block is run for the 6,12,24,16\n",
    "    for _ in range(repetition):\n",
    "      y = bn_rl_conv(x, 4*filters)    # Every 1x1 convolutions has 4-times the number of filters\n",
    "      y = bn_rl_conv(y, filters, 3)   # But 3x3 filters are oly present once\n",
    "\n",
    "    return x\n",
    "  \n",
    "  # Transition layer\n",
    "  # REmove channels to half of the existing channels \n",
    "  def transition_layer(x):\n",
    "    # K.int_shape(x) returns a tuple with the dimensions of x\n",
    "    # [-1] is the last dimension which is the filters.\n",
    "    # Since we need half of them we devide it by 2\n",
    "    x = bn_rl_conv(x, K.int_shape(x)[-1]//2)        # 1x1 convolution layer\n",
    "    x = AvgPool2D(2, strides=2, padding='same')(x)  # 2x2 average poolling layer with strid of 2\n",
    "    return x\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "  input = Input(input_shape)\n",
    "  # 1st convolution block with 64 filters of size 7x7 & a stride of 2:\n",
    "  x = Conv2D(64, 7, strides = 2, padding = \"same\")(input)\n",
    "  # Max pooling laxer with 3x3 max pooling & stride of 2\n",
    "  x = MaxPool2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "  # Run 4-times trough the 6, 12, 24, 16 repetitions\n",
    "  for repetition in [6,12,24,16]:\n",
    "    d = dense_block(x, repetition)\n",
    "    x = transition_layer(d)\n",
    "  print(x)\n",
    "  # Glabal average pooling\n",
    "  x = GlobalAveragePooling2D()(d)\n",
    "  print(x)\n",
    "  # Final dense output layer\n",
    "  output = Dense(n_classes, activation=\"softmax\")(x)\n",
    "  print(x)\n",
    "\n",
    "  model = Model(input, output)\n",
    "  return model\n",
    "\n",
    "\n",
    "## Compare to DenseNet121 from keras"
   ]
  },
  {
   "source": [
    "## Load the ground truth dataset\n",
    "* Import data and set column header\n",
    "* Sort by image_name (Should then be consistent with the images which will be sorted the same way.)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     image_name  patient_id     sex age_approx anatom_site_general_challenge  \\\n",
       "2  ISIC_0015719  IP_3075186  female       45.0               upper extremity   \n",
       "3  ISIC_0052212  IP_2842074  female       50.0               lower extremity   \n",
       "4  ISIC_0068279  IP_6890425  female       45.0                     head/neck   \n",
       "5  ISIC_0074268  IP_8723313  female       55.0               upper extremity   \n",
       "6  ISIC_0074311  IP_2950485  female       40.0               lower extremity   \n",
       "\n",
       "  diagnosis benign_malignant target  \n",
       "2   unknown           benign      0  \n",
       "3     nevus           benign      0  \n",
       "4   unknown           benign      0  \n",
       "5   unknown           benign      0  \n",
       "6   unknown           benign      0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>patient_id</th>\n      <th>sex</th>\n      <th>age_approx</th>\n      <th>anatom_site_general_challenge</th>\n      <th>diagnosis</th>\n      <th>benign_malignant</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0015719</td>\n      <td>IP_3075186</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0052212</td>\n      <td>IP_2842074</td>\n      <td>female</td>\n      <td>50.0</td>\n      <td>lower extremity</td>\n      <td>nevus</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0068279</td>\n      <td>IP_6890425</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ISIC_0074268</td>\n      <td>IP_8723313</td>\n      <td>female</td>\n      <td>55.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ISIC_0074311</td>\n      <td>IP_2950485</td>\n      <td>female</td>\n      <td>40.0</td>\n      <td>lower extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Set column headers\n",
    "head_list = [\"image_name\",\"patient_id\",\"sex\", \"age_approx\",\"anatom_site_general_challenge\", \"diagnosis\", \"benign_malignant\", \"target\"]\n",
    "\n",
    "# Load dataset @todo make reusable\n",
    "meta_train = pd.read_csv(\"C:\\\\Users\\\\clara\\\\DataSets\\\\ISIC_2020_Training_GroundTruth.csv\", names=head_list)\n",
    "\n",
    "# Sort values by image name\n",
    "meta_train.sort_values(by=['image_name'], inplace=True)\n",
    "\n",
    "# Display the dataset.\n",
    "meta_train.head()"
   ]
  },
  {
   "source": [
    "## Preprocess the Ground truth\n",
    "\n",
    "* Drop \"unknown\" diagnosis from CSV dataset\n",
    "* Store the image names to drop from the image dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         image_name  patient_id     sex  age_approx  \\\n",
       "3      ISIC_0052212  IP_2842074  female        50.0   \n",
       "13     ISIC_0076995  IP_2235340  female        55.0   \n",
       "27     ISIC_0084086  IP_4023055    male        60.0   \n",
       "28     ISIC_0084270  IP_2961528    male        40.0   \n",
       "29     ISIC_0084395  IP_0175539  female        45.0   \n",
       "...             ...         ...     ...         ...   \n",
       "33114  ISIC_9997614  IP_1705144  female        50.0   \n",
       "33118  ISIC_9998682  IP_2516168    male        60.0   \n",
       "33119  ISIC_9998937  IP_3091321    male        40.0   \n",
       "33126  ISIC_9999806  IP_0046310    male        45.0   \n",
       "0        image_name  patient_id     sex  age_approx   \n",
       "\n",
       "       anatom_site_general_challenge  diagnosis  benign_malignant  target  \n",
       "3                    lower extremity      nevus            benign       0  \n",
       "13                             torso      nevus            benign       0  \n",
       "27                   lower extremity      nevus            benign       0  \n",
       "28                   lower extremity      nevus            benign       0  \n",
       "29                             torso      nevus            benign       0  \n",
       "...                              ...        ...               ...     ...  \n",
       "33114                upper extremity      nevus            benign       0  \n",
       "33118                      head/neck   melanoma         malignant       1  \n",
       "33119                      head/neck      nevus            benign       0  \n",
       "33126                          torso      nevus            benign       0  \n",
       "0      anatom_site_general_challenge  diagnosis  benign_malignant  target  \n",
       "\n",
       "[6003 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>patient_id</th>\n      <th>sex</th>\n      <th>age_approx</th>\n      <th>anatom_site_general_challenge</th>\n      <th>diagnosis</th>\n      <th>benign_malignant</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0052212</td>\n      <td>IP_2842074</td>\n      <td>female</td>\n      <td>50.0</td>\n      <td>lower extremity</td>\n      <td>nevus</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>ISIC_0076995</td>\n      <td>IP_2235340</td>\n      <td>female</td>\n      <td>55.0</td>\n      <td>torso</td>\n      <td>nevus</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>ISIC_0084086</td>\n      <td>IP_4023055</td>\n      <td>male</td>\n      <td>60.0</td>\n      <td>lower extremity</td>\n      <td>nevus</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>ISIC_0084270</td>\n      <td>IP_2961528</td>\n      <td>male</td>\n      <td>40.0</td>\n      <td>lower extremity</td>\n      <td>nevus</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>ISIC_0084395</td>\n      <td>IP_0175539</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>torso</td>\n      <td>nevus</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33114</th>\n      <td>ISIC_9997614</td>\n      <td>IP_1705144</td>\n      <td>female</td>\n      <td>50.0</td>\n      <td>upper extremity</td>\n      <td>nevus</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33118</th>\n      <td>ISIC_9998682</td>\n      <td>IP_2516168</td>\n      <td>male</td>\n      <td>60.0</td>\n      <td>head/neck</td>\n      <td>melanoma</td>\n      <td>malignant</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33119</th>\n      <td>ISIC_9998937</td>\n      <td>IP_3091321</td>\n      <td>male</td>\n      <td>40.0</td>\n      <td>head/neck</td>\n      <td>nevus</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33126</th>\n      <td>ISIC_9999806</td>\n      <td>IP_0046310</td>\n      <td>male</td>\n      <td>45.0</td>\n      <td>torso</td>\n      <td>nevus</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>image_name</td>\n      <td>patient_id</td>\n      <td>sex</td>\n      <td>age_approx</td>\n      <td>anatom_site_general_challenge</td>\n      <td>diagnosis</td>\n      <td>benign_malignant</td>\n      <td>target</td>\n    </tr>\n  </tbody>\n</table>\n<p>6003 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Remove undefined diagnosis from dataset\n",
    "drop_images = []\n",
    "drop_idx = []\n",
    "for index, row in meta_train.iterrows(): \n",
    "    if row[\"diagnosis\"] == \"unknown\":\n",
    "        drop_images.append(row[\"image_name\"])\n",
    "        drop_idx.append(index)\n",
    "# Dop unknown values\n",
    "meta_train.drop(drop_idx)"
   ]
  },
  {
   "source": [
    "## Load the image dataset\n",
    "* Remove the images for which the diagnosis is unknown\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@TODO replace this with something reusable e.g. os.getcwd()\n",
    "imgPathFull = \"C:\\\\Users\\\\clara\\\\DataSets\\\\ISIC_2020_Training_JPEG\\\\train\\\\\"\n",
    "\n",
    "# Load and sort images\n",
    "imagePaths = sorted(list(os.listdir(imgPathFull)))\n",
    "\n",
    "# Remove unknown diagnosis\n",
    "filtered_paths = [i for i in imagePaths if i not in drop_images]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ground truth and images paths do not have compatible sizes\n"
     ]
    }
   ],
   "source": [
    "# Check if the shapes of ground truth and images are correct\n",
    "if (meta_train.shape[0] != len(filtered_paths)):\n",
    "    print(\"Ground truth and images paths do not have compatible sizes\")\n",
    "    #@TODO end process otherwise"
   ]
  },
  {
   "source": [
    "## Load & preprocess the images\n",
    "* Resize them to (224, 224)\n",
    "* Convert them to numpy arrays\n",
    "* Generate the labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100/2000 files processed; 6.077 data/s\n",
      "200/2000 files processed; 7.198 data/s\n",
      "300/2000 files processed; 7.075 data/s\n",
      "400/2000 files processed; 7.151 data/s\n",
      "500/2000 files processed; 7.404 data/s\n",
      "600/2000 files processed; 7.498 data/s\n",
      "700/2000 files processed; 7.334 data/s\n",
      "800/2000 files processed; 7.261 data/s\n",
      "900/2000 files processed; 7.166 data/s\n",
      "1000/2000 files processed; 7.12 data/s\n",
      "1100/2000 files processed; 7.157 data/s\n",
      "1200/2000 files processed; 7.147 data/s\n",
      "1300/2000 files processed; 7.071 data/s\n",
      "1400/2000 files processed; 7.076 data/s\n",
      "1500/2000 files processed; 7.088 data/s\n",
      "1600/2000 files processed; 7.027 data/s\n",
      "1700/2000 files processed; 6.971 data/s\n",
      "1800/2000 files processed; 6.921 data/s\n",
      "1900/2000 files processed; 6.89 data/s\n",
      "2000/2000 files processed; 6.891 data/s\n"
     ]
    }
   ],
   "source": [
    "#@TODO optimize this (takes too much time) \n",
    "# We could e.g. use tfrecords or sth.\n",
    "data=[]\n",
    "labels=[]\n",
    "counter = 0\n",
    "maxcount = len(filtered_paths)\n",
    "# Comment this out to use the whole dataset\n",
    "maxcount = 2000\n",
    "tic = time.time()\n",
    "# Decide how often you want to print the progress\n",
    "print_per = 100\n",
    "for index, row in meta_train.iterrows():\n",
    "    if (counter >= maxcount):\n",
    "        break    \n",
    "    img = imagePaths[counter]\n",
    "    img_path = imgPathFull+ img   \n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "    labels.append(row[\"diagnosis\"])\n",
    "    counter += 1\n",
    "    if (counter%print_per == 0):\n",
    "        duration = time.time()-tic\n",
    "        print(\"{}/{} files processed; {:.4} data/s\".format(counter, maxcount, float(counter)/duration))\n"
   ]
  },
  {
   "source": [
    "### Conversion of Labels & Data\n",
    "* Binarize labels in a one-vs-all fashion.\n",
    "* Convert data to np.array"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@TODO we need to change this as e.g. my computer cannot handle the conversion to np.array for the whole dataset\n",
    "\n",
    "# Convert from cathegorical to numerical\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Count the unique values in the diagnosis column\n",
    "num_lables = len(np.unique(labels))\n",
    "\n",
    "mlb = LabelBinarizer()\n",
    "bin_labels = mlb.fit_transform(labels)\n",
    "data = np.array(data, dtype=\"float32\") / 255.0"
   ]
  },
  {
   "source": [
    "## Generate Model\n",
    "* Use the number of labels for generation\n",
    "* Display a summary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensor(\"average_pooling2d_3/Identity:0\", shape=(None, 4, 4, 4), dtype=float32)\nTensor(\"global_average_pooling2d/Identity:0\", shape=(None, 8), dtype=float32)\nTensor(\"global_average_pooling2d/Identity:0\", shape=(None, 8), dtype=float32)\nModel: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 112, 112, 64)      9472      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 56, 56, 64)        0         \n_________________________________________________________________\nbatch_normalization_12 (Batc (None, 56, 56, 64)        256       \n_________________________________________________________________\nre_lu_12 (ReLU)              (None, 56, 56, 64)        0         \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 56, 56, 32)        2080      \n_________________________________________________________________\naverage_pooling2d (AveragePo (None, 28, 28, 32)        0         \n_________________________________________________________________\nbatch_normalization_37 (Batc (None, 28, 28, 32)        128       \n_________________________________________________________________\nre_lu_37 (ReLU)              (None, 28, 28, 32)        0         \n_________________________________________________________________\nconv2d_38 (Conv2D)           (None, 28, 28, 16)        528       \n_________________________________________________________________\naverage_pooling2d_1 (Average (None, 14, 14, 16)        0         \n_________________________________________________________________\nbatch_normalization_86 (Batc (None, 14, 14, 16)        64        \n_________________________________________________________________\nre_lu_86 (ReLU)              (None, 14, 14, 16)        0         \n_________________________________________________________________\nconv2d_87 (Conv2D)           (None, 14, 14, 8)         136       \n_________________________________________________________________\naverage_pooling2d_2 (Average (None, 7, 7, 8)           0         \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 8)                 0         \n_________________________________________________________________\ndense (Dense)                (None, 6)                 54        \n=================================================================\nTotal params: 12,718\nTrainable params: 12,494\nNon-trainable params: 224\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We currently need to wait till here since we do not use the whole dataset & therfore we do not know how many labels are currently present.\n",
    "input_shape = 224,224, 3\n",
    "\n",
    "model = densenet(input_shape, num_lables)\n",
    "model.summary()"
   ]
  },
  {
   "source": [
    "### Avoid overfitting\n",
    "* change once network has been optimized"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 112, 112, 64)      9472      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 56, 56, 64)        0         \n_________________________________________________________________\nbatch_normalization_12 (Batc (None, 56, 56, 64)        256       \n_________________________________________________________________\nre_lu_12 (ReLU)              (None, 56, 56, 64)        0         \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 56, 56, 32)        2080      \n_________________________________________________________________\naverage_pooling2d (AveragePo (None, 28, 28, 32)        0         \n_________________________________________________________________\nbatch_normalization_37 (Batc (None, 28, 28, 32)        128       \n_________________________________________________________________\nre_lu_37 (ReLU)              (None, 28, 28, 32)        0         \n_________________________________________________________________\nconv2d_38 (Conv2D)           (None, 28, 28, 16)        528       \n_________________________________________________________________\naverage_pooling2d_1 (Average (None, 14, 14, 16)        0         \n_________________________________________________________________\nbatch_normalization_86 (Batc (None, 14, 14, 16)        64        \n_________________________________________________________________\nre_lu_86 (ReLU)              (None, 14, 14, 16)        0         \n_________________________________________________________________\nconv2d_87 (Conv2D)           (None, 14, 14, 8)         136       \n_________________________________________________________________\naverage_pooling2d_2 (Average (None, 7, 7, 8)           0         \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 8)                 0         \n_________________________________________________________________\ndense (Dense)                (None, 6)                 54        \n=================================================================\nTotal params: 12,718\nTrainable params: 750\nNon-trainable params: 11,968\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[:-8]:\n",
    "    layer.trainable=False\n",
    "    \n",
    "for layer in model.layers[-8:]:\n",
    "    layer.trainable=True\n",
    "model.summary()"
   ]
  },
  {
   "source": [
    "## Create train/test split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@TODO change this to use the test dataset instead of this split\n",
    "(xtrain,xtest,ytrain,ytest)=train_test_split(data,bin_labels,test_size=0.2,random_state=42)"
   ]
  },
  {
   "source": [
    "## Additional Preprocessing\n",
    "* Reduce learning rate when a metric has stopped improving.\n",
    "\n",
    "* Create Checkpoint\n",
    "* Create image batches with real-time augmentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "anne = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-3)\n",
    "\n",
    "checkpoint = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "datagen = ImageDataGenerator(zoom_range = 0.2, horizontal_flip=True, shear_range=0.2)"
   ]
  },
  {
   "source": [
    "## Fit the Data & Compile tha Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(data)\n",
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-3ffea3cc894d>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.57376, saving model to model.h5\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.57376 to 1.49593, saving model to model.h5\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.49593 to 1.41927, saving model to model.h5\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.41927 to 1.34532, saving model to model.h5\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.34532 to 1.27295, saving model to model.h5\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.27295 to 1.20209, saving model to model.h5\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.20209 to 1.13226, saving model to model.h5\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.13226 to 1.06750, saving model to model.h5\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.06750 to 1.00871, saving model to model.h5\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.00871 to 0.95543, saving model to model.h5\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.95543 to 0.90836, saving model to model.h5\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.90836 to 0.86656, saving model to model.h5\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.86656 to 0.83118, saving model to model.h5\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.83118 to 0.80131, saving model to model.h5\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.80131 to 0.77452, saving model to model.h5\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.77452 to 0.75172, saving model to model.h5\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.75172 to 0.73194, saving model to model.h5\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.73194 to 0.71451, saving model to model.h5\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.71451 to 0.69968, saving model to model.h5\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.69968 to 0.68673, saving model to model.h5\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.68673 to 0.67707, saving model to model.h5\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.67707 to 0.66924, saving model to model.h5\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.66924 to 0.66118, saving model to model.h5\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.66118 to 0.65106, saving model to model.h5\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.65106 to 0.64273, saving model to model.h5\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.64273 to 0.63595, saving model to model.h5\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.63595 to 0.62635, saving model to model.h5\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.62635 to 0.61907, saving model to model.h5\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.61907 to 0.61375, saving model to model.h5\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.61375 to 0.60824, saving model to model.h5\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.60824 to 0.60240, saving model to model.h5\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.60240 to 0.59428, saving model to model.h5\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.59428 to 0.58587, saving model to model.h5\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.58587 to 0.58094, saving model to model.h5\n",
      "Epoch 35/50\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.58094 to 0.57659, saving model to model.h5\n",
      "Epoch 36/50\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.57659 to 0.57388, saving model to model.h5\n",
      "Epoch 37/50\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.57388 to 0.56975, saving model to model.h5\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.56975 to 0.56584, saving model to model.h5\n",
      "Epoch 39/50\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.56584 to 0.55820, saving model to model.h5\n",
      "Epoch 40/50\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.55820 to 0.54988, saving model to model.h5\n",
      "Epoch 41/50\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.54988 to 0.54329, saving model to model.h5\n",
      "Epoch 42/50\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.54329 to 0.53539, saving model to model.h5\n",
      "Epoch 43/50\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.53539 to 0.53054, saving model to model.h5\n",
      "Epoch 44/50\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.53054 to 0.52206, saving model to model.h5\n",
      "Epoch 45/50\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.52206 to 0.51291, saving model to model.h5\n",
      "Epoch 46/50\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.51291 to 0.50445, saving model to model.h5\n",
      "Epoch 47/50\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.50445 to 0.49152, saving model to model.h5\n",
      "Epoch 48/50\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.49152 to 0.48132, saving model to model.h5\n",
      "Epoch 49/50\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.48132 to 0.46919, saving model to model.h5\n",
      "Epoch 50/50\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.46919 to 0.45850, saving model to model.h5\n"
     ]
    }
   ],
   "source": [
    "#@TODO use model.fit instead (due to deprication)\n",
    "history = model.fit_generator(datagen.flow(xtrain, ytrain, batch_size=224),\n",
    "               steps_per_epoch=xtrain.shape[0] //224,\n",
    "               epochs=50,\n",
    "               verbose=num_lables,\n",
    "               callbacks=[anne, checkpoint],\n",
    "               validation_data=(xtrain, ytrain))"
   ]
  },
  {
   "source": [
    "## Test the Data\n",
    "\n",
    "* Predict the test split\n",
    "* Display how many we predicted correctly.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total-test-data; 400 \taccurately-predicted-data: 353 \t wrongly-predicted-data:  47\nAccuracy: 88.25 %\n"
     ]
    }
   ],
   "source": [
    "ypred = model.predict(xtest)\n",
    "\n",
    "total = 0\n",
    "accurate = 0\n",
    "accurateindex = []\n",
    "wrongindex = []\n",
    "\n",
    "for i in range(len(ypred)):\n",
    "    if np.argmax(ypred[i]) == np.argmax(ytest[i]):\n",
    "        accurate += 1\n",
    "        accurateindex.append(i)\n",
    "    else:\n",
    "        wrongindex.append(i)\n",
    "        \n",
    "    total += 1\n",
    "    \n",
    "print('Total-test-data;', total, '\\taccurately-predicted-data:', accurate, '\\t wrongly-predicted-data: ', total - accurate)\n",
    "print('Accuracy:', round(accurate/total*100, 3), '%')"
   ]
  },
  {
   "source": [
    "## Make a confusion matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### General TODOs\n",
    "* use train-test dataset\n",
    "* upload dataset to azure\n",
    "* CLUSTERING! before (consider that there are hairy images aswell)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### References:\n",
    "* [pluralsight](https://www.pluralsight.com/guides/introduction-to-densenet-with-tensorflow)\n",
    "* [towardsdatascience](https://towardsdatascience.com/creating-densenet-121-with-tensorflow-edbc08a956d8)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}